\documentclass[journal]{IEEEtran}
%\documentclass[12pt,journal,draftclsnofoot,onecolumn]{IEEEtran}
%\documentclass[conference]{IEEEtran}

\IEEEoverridecommandlockouts

\usepackage{etex}

%Fixing IEEEtran.cls bug with [english]{babel}
\makeatletter
\def\markboth#1#2{\def\leftmark{\@IEEEcompsoconly{\sffamily}\MakeUppercase{\protect#1}}%
\def\rightmark{\@IEEEcompsoconly{\sffamily}\MakeUppercase{\protect#2}}}
\makeatother

% \usepackage{t1enc}

\usepackage{listings}

%\usepackage[utf8x]{inputenc}
\usepackage[english]{babel}
\selectlanguage{english}
\usepackage{color}
\usepackage{lipsum}% http://ctan.org/pkg/lipsum
%\usepackage{caption}
\usepackage{cite}
\usepackage[pdftex]{graphicx}
%\usepackage{subfig}
%\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{array}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{url}
\usepackage{enumerate}
\usepackage{multirow}

\usepackage{epsfig}
\usepackage{epstopdf}
\usepackage{multicol}% http://ctan.org/pkg/multicols
\usepackage[font=footnotesize]{caption}
\usepackage[font=scriptsize]{subcaption}
% Tikz
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\pgfplotsset{plot coordinates/math parser=false}
\newlength\fheight
\newlength\fwidth
\usetikzlibrary{patterns,decorations.pathreplacing,backgrounds,calc}
\definecolor{SchoolColor}{RGB}{0.71, 0, 0.106}%181,0,27} unipd red
\definecolor{chaptergrey}{rgb}{0.61, 0, 0.09} % dialed back a little
\definecolor{midgrey}{rgb}{0.4, 0.4, 0.4}
\definecolor{chaptergreen}{rgb}{0.09, 0.612, 0}
\definecolor{chapterpurple}{rgb}{0.522, 0, 0.612}
\definecolor{chapterlightgreen}{rgb}{0, 0.612, 0.522}

%\raggedbottom

% Pseudocode
\usepackage[ruled, vlined]{algorithm2e}

\SetKwRepeat{Do}{do}{while}
\SetKwBlock{wpPa}{with probability $P_A$}{end}
\DontPrintSemicolon
% \usepackage{algorithm}
% \usepackage[noend]{algpseudocode}
% \renewcommand\algorithmicthen{}
% \renewcommand\algorithmicdo{}
\usepackage{lscape}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}

\newcommand{\field}[1]{\mathbb{#1}}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\renewcommand{\arraystretch}{2}

\newcommand{\DP}[1]{\textbf{(DP: #1)}}
\newcommand{\el}[1]{\textr{(EL says: #1)}}
\newcommand{\fm}[1]{\texbf{(FM says: #1)}}

\usepackage{threeparttable}
%\usepackage[table,xcdraw]{xcolor}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{booktabs}
\newcommand{\tabitem}{~~\llap{\textbullet}~~}
\usepackage{array, blindtext}
\usepackage{wrapfig}
\usepackage{pdfpages}
\usepackage[acronym]{glossaries}

% use tikArchiviz images or eps
\newif\iftikz
\tikztrue

\graphicspath{{./figures/}}

\title{Heuristic optimization of Distributed Storage Network techniques}
\author{\IEEEauthorblockN{Federico Mason$^*$, Davide Peron$^*$, Enrico Lovisotto$^*$}\\
\small{{$^*$Department of Information Engineering, University of Padova -- Via Gradenigo, 6/b, 35131 Padova, Italy\\
Email: {\tt\{masonfed,perondav,lovisott\}@dei.unipd.it}\\}}
}

% Reduce the space below figs.
%\setlength{\belowcaptionskip}{-0.7cm}

%% Glossary
\newacronym{dsn}{DSN}{Distributed Storage Network}
\newacronym{edfc}{EDFC}{Exact Decentralized Fountain Codes}
\newacronym{adfc}{ADFC}{Approximate Decentralized Fountain Codes}
\newacronym{sa}{SA}{Simulated Annealing}
\newacronym{ga}{GA}{Genetic Algorithm}
\newacronym{jb}{JB}{Jumping Ball}
\newacronym{wsn}{WSN}{Wireless Sensor Network}
\newacronym{fp}{FP}{First Problem}
\newacronym{sp}{SP}{Second Problem}
\newacronym{of}{$f$}{Objective Function}
\newacronym{t}{T}{Temperature}
\newacronym{oc}{$x_o$}{Old Candidate}
\newacronym{nc}{$x_n$}{New Candidate}
\newacronym{sc}{$C_S$}{Step Coefficient}
\newacronym{ac}{$C_A$}{Acceptance Coefficient}
\newacronym{ap}{$P_A$}{Acceptance Probability}
\newacronym{ws}{$N_{WS}$}{Number of Worsening Steps}
\newacronym{wsmax}{$N_{WS}^{MAX}$}{ Maxiumum Number of Worsening Steps}
\newacronym{x}{x}{Candidate}
\newacronym{bestx}{$x_{best}$}{Best candidate}

\glsresetall
\begin{document}

\setlength{\belowcaptionskip}{-0.2cm}

% reduce space after title
\makeatletter
\patchcmd{\@maketitle}
  {\addvspace{0.5\baselineskip}\egroup}
  {\addvspace{-1.2\baselineskip}\egroup}
  {}
  {}
\makeatother

\maketitle

\begin{abstract}
In some previous works about \gls{dsn}, two packet spreading algorithm are presented, \gls{edfc} and \gls{adfc}.

Unfortunately the tuning of their fundamental parameters, $x_d$ and $\nu(d)$ respectively, was not thoroughly investigated.

We try to perform such tuning applying some heuristic optimization techniques, such as \emph{Simulated Annealing} and \emph{Genetic Algorithm}, in order to explore the solution space of the problem.

\end{abstract}

\begin{IEEEkeywords}
Distributed Storage Networks, sensors, heuristic optimization
\end{IEEEkeywords}

\glsresetall
\label{sec:introduction}
We consider a \gls{wsn} whose nodes are distributed over a known region.
Some of them, called \textit{sensing nodes}, collect and deploy data from the environment (temperature, pressure, motion data, \ldots) while the others, called \textit{caching nodes}, simply store data coming from \textit{sensing nodes}.

In literature, a \gls{wsn} often has a central node, a powered sink connected to the internet.
Such special node receives all information collected by the nodes in the network and provides it to the users.

However, in our paper, following what has been done in \cite{Lin2007}, we get rid of this assumption.
Users then must collect the data stored in the network visiting the geographical region where system is located.

In such a scenario, user visits only a certain number $h$ of nodes of the network.
Our reference paper \cite{Lin2007}, guarantees source packets decodability using \emph{Random Fountain Codes}, combining and spreading $K$ source packets across $N$ total nodes such that, using any group of $K+\epsilon$ of them (with $\epsilon$ constant in $K$), the original information can be successfully retrieved with high probability.

The challenge here is to keep the communication cost at a minimum level, while keeping the failure probability low.

Traditional but expensive two-way packet delivery is then discarded, in favour of one-way \emph{random walks}.
Random walks are designed according to \emph{Metropolis algorithm} such that the number of packets reaching each node resembles the Robust Soliton distribution, whose optimal decoding properties are known\cite{Luby}.

In this paper, we are going to find the optimal $x_d$ and $\nu(d)$ parameters for \gls{edfc} and \gls{adfc} respectively, with three different heuristics.

The optimal configurations are then tested with a network simulator, where further analysis is performed.

The article is structured in three sections.

In \autoref{sec:tech_approach} we present in detail the heuristic algorithms employed, first with a general description of the framework and then fucusing on our specific problem.

In \autoref{sec:results} we present the results obtained using the optimal parameter configurations in the network simulator we have implemented.

\section{Technical Approach}
\label{sec:tech_approach}

\gls{edfc} and \gls{adfc} spreading algorithms require to be tuned, with their parameters $x_d$ and $\nu(d)$.

$x_d$ is a K-dimensional variable of \gls{edfc} called \textit{redundancy coefficent}. Given a node with \textit{code degree} $d$, $x_d \cdot d$ represents the number of packets that should be received by the node itself at the end of packets spread.

The best value of $x_d$ is the solution of the following optimization problem\cite{Lin2007}.

\begin{equation}
	\label{firstproblem}
	\begin{split}
		minimize & \sum_{d=1}^K x_d d \mu (d) \\
		subject \ to & \begin{dcases}
			Pr(Y<d|X=d) \leq \delta_d \\
			x_d \geq 1 \quad for \quad d = 1,...,K
		\end{dcases}
	\end{split}
\end{equation}

$\nu$ is instead the degree distribution of network nodes such that, after package spread, the resulting degree distribution $\nu^\prime$ is as close as possible to the \textit{Robust Soliton Distribution}.

The optimal $\nu(d)$ is the solution of the following optimization problem\cite{Lin2007}.

\begin{equation}
	\label{secondproblem}
	\begin{split}
		minimize & \quad \sum_{i=1}^{K/R}(\nu'(i)-\mu(i))^2 \\
		subject \ to & \quad \begin{cases}
			\sum_{i=1}^K \nu(i) = 1 \\
			\nu(i) \geq 0 \quad for \quad i=1,...,K
		\end{cases}
	\end{split}
\end{equation}

given
\begin{equation*}
	\begin{split}
		& v^\prime(i) = \sum_{d=1}^K \nu(d) \binom{K}{i} p(d)^i [1-p(d)]^{K-i} \\
		& p(d) = 1 - \left(1 -\frac{d}{N E}\right)^{\frac{N E}{K}} \\
		& E = \text{ expected value of }\nu
	\end{split}
\end{equation*}

From now on, we call \eqref{firstproblem} and \eqref{secondproblem} simply \gls{fp} and \gls{sp}.

We see immediately that \gls{fp} and \gls{sp} are not solvable with \emph{convex optimization} tecniques, as they don't minimize convex objective functions over convex sets.

To overcome this issue, we chose the heuristic approach, whose convergence to the optimum is not guaranteed in polynomial time, but whose effectiveness has been proven in many fields \cite{Edelkamp2010} where traditional tools (such as \emph{Simplex}) cannot be applied.

In fact they reach solutions that are often suboptimal but still useful for our purposes.

\subsection{Simulated Annealing}

The first algorithm we implement is known as \gls{sa}.
\gls{sa} is a probabilistic technique that takes ispiration from annealing in metallurgy, a process that aims to reduce materials defects.
In this physical process a piece of metal is warmed at high temperatures and then slowly cooled. In this way it is possible to achieve the molecular equilibrium inside the material itself.

In \gls{sa}, we treat \gls{of} as the internal energy of the material.
As in the physical process we want to reduce the function energy and the slowly bring it to a stable value. In other words we want first cross widely the function domain and then concentrate in the points with higher probability to be the absolute minimum of \gls{of}.

\gls{sa} behaviour is dependent on a parameter called \gls{t}: relevant for the search are \gls{sc} and \gls{ac}, the number of points to inspect for given \gls{t} and the probability $P_A$ of accepting a point worse than the current, respectively.

At the beginning \gls{t} is initialized at a sufficient high value and then it is reduced at each algorithm step.

The process starts at a random point that respect problem constraints. Each new point $\vec{x}_{new}$ is found \emph{perturbing} previous vector $\vec{x}$ until one is found that respects problem constraints.

Empirically, we found for the two problems two different perturbation strategies, i.e. \emph{Neighbour} function in pseudocodes.
For \gls{fp} we add an uniform variable, whose range is proportional to temperature, to a randomly chosen component of the $\vec{x}$ vector, while for \gls{sp} we perturb ``moving'' some probability from one degree to one other, chosen uniformly across the distribution.

Such solution is kept or rejected according to the \gls{ap}, whose expression is the following.

 \begin{equation*} \label{accept_prob}
	P_A(T) = \begin{cases}
		1 & f(\vec{x}_n)-f (\vec{x}_o) < 0 \\
		\exp{ \left( C_A(T) \frac{
					\, [f(\vec{x}_n) - f(\vec{x}_o)] }{T} \right) }
		& f (\vec{x}_n)-f(\vec{x}_o) \geq 0
  \end{cases}
 \end{equation*}

The best point among all the explored ones is kept across the path and it is returned at the end of the computation.

The algorithm is provided here as pseudocode in \autoref{algo:SA}.

\begin{algorithm}
\KwIn{Objective function $f$ and constraints, Initial Temperature,  Maximum number of steps, Steps Coefficient, Acceptance Coefficient}
\KwOut{Optimal solution}
\caption{Simulated Annealing} \label{algo:SA}

$T \gets$ Initial Temperature \\
$x \gets$ Random valid point() \\
$x_{best} \gets x$ \\
$C_A \gets$ Acceptance coefficient \\
$N_S \gets 0$ \\
$N_S^{MAX} \gets $ Maximum number of steps \\

\While{$N_S < N_S^{MAX}$} {
	$C_S \gets$ Steps coefficient ($T$) \\
	\For{$i = 1$ to $C_S$} {
		$\vec{x}_{new} \gets$ Neighbour$(\vec{x})$\\
		$P_A \gets$ Acceptance probability($\vec{x}$, $\vec{x}_{new}$, $C_A$) \\
		\wpPa {
			$\vec{x} \gets \vec{x}_{new}$\\
		}
		\If{$f(x)<f(x_{best})$}{
			$x_{best} \gets x$\\
		}
		Increment $N_S$
	}
	update $T$\\
	update $C_S$\\
}
\Return{$x_{best}$}
\end{algorithm}

\subsection{Jumping Ball}

Our second search algorithm is a variation of \gls{sa}, designed, implemented by our group and called \gls{jb}.

Its approach rose from the observation that if the cooling phase of \gls{sa} takes to a sub-optimal region of the solution space there is no way to leave it for a better one.

So, we develop the heuristic of \emph{jumps}, whose aim is to overcome this issue. If the best solution available is not improved for a certain number $N_{WS}^{MAX}$ of small perturbation, as done in \gls{sa}, a big shock, called \emph{jump}, is introduced in $\vec{x}$ components.

This parameter has to be initialized properly: a value too low would lead the algorithm to jump indefinitely without ever stabilizing in a single area, but a value too high would make jumps impossible, making pointless this heuristic and leading to \gls{sa} algorithm.

A proper value of $N_{WS}^{MAX}$ enhances the exploration space of the \gls{sa} algorithm, leading to better results in our variant \gls{jb}.

The pseudocode for \gls{jb} is the same as \gls{sa}, the different \emph{Neighbour} function is described in \autoref{algo:JB_neigh}.

\begin{algorithm}
	\caption{Jumping Ball \emph{Neighbour}}\label{algo:JB_neigh}
	\KwIn{Problem constraints and objective function $f$, $\vec{x}$, $N_{WS}^{MAX}$, current number of worsening steps $N_{WS}$}
	\KwOut{$\vec{x}_{new}$}
	\Repeat{$\vec{x}_{new}$ respects constraints} {

		$\vec{x}_{new} \gets \vec{x}$ \\

		\If { $N_{WS} > N_{WS}^{MAX}$ } {

			\Repeat{$\vec{x}_{new}$ respects constraints} {

				Perturb an random number of components of $\vec{x}_{new}$

			}
			$N_{WS}$ = 0
		}
		\Else {
			Perturb just one component of $\vec{x}_{new}$ in $[1, K]$
		}
	}

	\If { $f(\vec{x}_{new}) > f(\vec{x}_{best})$  } {

		Increment $N_{WS}$
	}
	\Return $\vec{x}_{new}$
\end{algorithm}

\subsection{Genetic Algorithm}
The third technique is called Genetic Algorithm.
The algorithm takes randomly an initial set of solution for the problem, called \textit{population}, and tries to evolve it toward better solutions.
Each candidate solution is called \textit{individual}, that is usually a multi-dimensional array. In biological applications, each component of the individual is a \textit{chromosome} or a \textit{genotype}, in our case it is simply an entry for the array.

\gls{ga} is an iterative process, in each iteration, the population is evolved in a new \textit{generation}.
In each generation, the objective function of each individual is evaluated. The best individuals (in terms of objective function) are selected and mutated to create the next generation.

The way in which an individual is mutated can be arbitrarily chosen.
Usually one or more components are perturbated randomly, or parts of different solutions are joined togheter, to maintain the properties of the old solutions trying to improve it.
In this work we have decided to perturbe each individual up to 3 times, the number of perturbation will be the one that leads to a better objective function.

\begin{algorithm}
\KwIn{Objective function and constraints, \textit{survival rate}, \textit{max generations}, $\norm{population}$}
\KwOut{Optimal solution}
$generation \gets 0$\\
$\textit{best part size} \gets \norm{population} \cdot \textit{survival rate}$\\
$population \gets \textit{initial population}$\\
\While{$generation < \textit{max generations}$}{
  sort(\textit{population})\\
  \For{$j=1$ to round($1/\textit{survival rate}$)}{
    \For{$i=1$ to \textit{best part size}}{
      $population(j \cdot \textit{best part size} + i) \gets population(i)$\\
      \Do{! respect Constraints}{
        $individual \gets population(j \cdot \textit{best part size} + i)$\\
        $candidates(0) \gets individual + perturbation$\\
        $candidates(1) \gets candidate(0) + perturbation$\\
        $candidates(2) \gets candidate(1) + perturbation$\\
        sort(\textit{candidates})\\
        $individual \gets candidates(0)$
      }
      $population(j \cdot \textit{best part size} + i) \gets individual$
    }
  }
  \textit{generation++}
}
\Return{$population(0)$}\;
\caption{Genetic Algorithm}\label{algo:GA}
\end{algorithm}

The parameters that can be tuned in order to achieve the best result are:
\begin{description}
	\item[\textbf{Survival Rate}] \hfill \\
	The fraction of population that is used to create the next generation;
	\item[\textbf{Max Generations}] \hfill \\
	Number of generations created, this is actually the number of iteration of the algorithm. The duration of the computation is linearly dependent on this parameter.
	\item[$\norm{population}$] \hfill \\
	Number of individual in a population. This parameter affects the computational complexity of the algorithm. The larger the population, the more time will pass from one generation to another, since in each generation the objective function for each individual is computed.
\end{description}

\section{Results}
\label{sec:results}
\begin{figure}
  \centering
	    \includegraphics[width=0.9\columnwidth]{ratiovsprob.eps}
  \caption{Successfull decoding probability $P_s$ for different values of $N$, $K$ and decoding ratio $\nu$.}
  \label{fig:ratiovsprob}
\end{figure}

\section{Conclusions And Future Work}
\label{sec:conclusions}

\bibliographystyle{IEEEtran}
\bibliography{bibliography}

\end{document}
